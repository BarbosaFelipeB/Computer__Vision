{"cells":[{"cell_type":"markdown","metadata":{},"source":["This Notebook is copied and edited from ADITYA SHARMA work: https://www.kaggle.com/adityasharma01/brain-tumor-kerastuner."]},{"cell_type":"markdown","metadata":{},"source":["# Load Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:12:35.164739Z","iopub.status.busy":"2021-10-18T18:12:35.164156Z","iopub.status.idle":"2021-10-18T18:12:42.350860Z","shell.execute_reply":"2021-10-18T18:12:42.349880Z","shell.execute_reply.started":"2021-10-18T18:12:35.164649Z"},"trusted":true},"outputs":[],"source":["import os\n","import glob\n","\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","\n","import random\n","from tqdm.notebook import tqdm\n","import pydicom # Handle MRI images\n","\n","import cv2  # OpenCV - https://docs.opencv.org/master/d6/d00/tutorial_py_root.html\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import layers\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load Datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:12:49.471671Z","iopub.status.busy":"2021-10-18T18:12:49.471074Z","iopub.status.idle":"2021-10-18T18:12:49.520041Z","shell.execute_reply":"2021-10-18T18:12:49.518983Z","shell.execute_reply.started":"2021-10-18T18:12:49.471637Z"},"trusted":true},"outputs":[],"source":["data_dir = Path('../input/rsna-miccai-brain-tumor-radiogenomic-classification/')\n","\n","mri_types = [\"FLAIR\", \"T1w\", \"T2w\", \"T1wCE\"]\n","excluded_images = [109, 123, 709] # Bad images\n","\n","train_df = pd.read_csv(data_dir / \"train_labels.csv\")\n","test_df = pd.read_csv(data_dir / \"sample_submission.csv\")\n","sample_submission = pd.read_csv(data_dir / \"sample_submission.csv\")\n","\n","train_df = train_df[~train_df.BraTS21ID.isin(excluded_images)]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Utility Functions"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:12:54.592023Z","iopub.status.busy":"2021-10-18T18:12:54.591324Z","iopub.status.idle":"2021-10-18T18:12:54.612158Z","shell.execute_reply":"2021-10-18T18:12:54.610769Z","shell.execute_reply.started":"2021-10-18T18:12:54.591990Z"},"trusted":true},"outputs":[],"source":["def load_dicom(path, size = 512):\n","    ''' \n","    Reads a DICOM image, standardizes so that the pixel values are between 0 and 1, then rescales to 0 and 255\n","    \n","    Not super sure if this kind of scaling is appropriate, but everyone seems to do it. \n","    '''\n","    dicom = pydicom.read_file(path)\n","    data = dicom.pixel_array\n","    # transform data into black and white scale / grayscale\n","#     data = data - np.min(data)\n","    if np.max(data) != 0:\n","        data = data / np.max(data)\n","    data = (data * 255).astype(np.uint8)\n","    return cv2.resize(data, (size, size))\n","\n","def get_all_image_paths(brats21id, image_type, folder='train'): \n","    '''\n","    Returns an arry of all the images of a particular type for a particular patient ID\n","    '''\n","    assert(image_type in mri_types)\n","    \n","    patient_path = os.path.join(\n","        \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/%s/\" % folder, \n","        str(brats21id).zfill(5),\n","    )\n","\n","    paths = sorted(\n","        glob.glob(os.path.join(patient_path, image_type, \"*\")), \n","        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n","    )\n","    \n","    num_images = len(paths)\n","    \n","    start = int(num_images * 0.25)\n","    end = int(num_images * 0.75)\n","\n","    interval = 3\n","    \n","    if num_images < 10: \n","        interval = 1\n","    \n","    return np.array(paths[start:end:interval])\n","\n","def get_all_images(brats21id, image_type, folder='train', size=512):\n","    return [load_dicom(path, size) for path in get_all_image_paths(brats21id, image_type, folder)]\n","\n","def get_all_data_for_train(image_type, image_size=413):\n","    global train_df\n","    \n","    X = []\n","    y = []\n","    train_ids = []\n","\n","    for i in tqdm(train_df.index):\n","        x = train_df.loc[i]\n","        images = get_all_images(int(x['BraTS21ID']), image_type, 'train', image_size)\n","        label = x['MGMT_value']\n","\n","        X += images\n","        y += [label] * len(images)\n","        train_ids += [int(x['BraTS21ID'])] * len(images)\n","        assert(len(X) == len(y))\n","    return np.array(X), np.array(y), np.array(train_ids)\n","\n","def get_all_data_for_test(image_type, image_size=512):\n","    global test_df\n","    \n","    X = []\n","    test_ids = []\n","\n","    for i in tqdm(test_df.index):\n","        x = test_df.loc[i]\n","        images = get_all_images(int(x['BraTS21ID']), image_type, 'test', image_size)\n","        X += images\n","        test_ids += [int(x['BraTS21ID'])] * len(images)\n","\n","    return np.array(X), np.array(test_ids)"]},{"cell_type":"markdown","metadata":{},"source":["# Load all Images\n","```\n","X - contains all the images for each patient \n","trainidt - trainidt is a mask vector into X, y for training.  There's a patient id/BraTS21ID corresponding to each image (e.g. (0, 0, 0, 0, 2,2, 3,3,3,3,3,...) )\n","testidt - testidt is a mask vector into X_test for testing\n","```"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:13:08.303421Z","iopub.status.busy":"2021-10-18T18:13:08.302521Z","iopub.status.idle":"2021-10-18T18:16:37.063684Z","shell.execute_reply":"2021-10-18T18:16:37.062517Z","shell.execute_reply.started":"2021-10-18T18:13:08.303387Z"},"trusted":true},"outputs":[],"source":["X, y, trainidt = get_all_data_for_train('T1wCE', image_size=32)\n","X_test, testidt = get_all_data_for_test('T1wCE', image_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["# Train/Validation Split"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:16:43.384055Z","iopub.status.busy":"2021-10-18T18:16:43.383664Z","iopub.status.idle":"2021-10-18T18:16:43.406760Z","shell.execute_reply":"2021-10-18T18:16:43.405793Z","shell.execute_reply.started":"2021-10-18T18:16:43.384010Z"},"trusted":true},"outputs":[],"source":["X_train, X_valid, y_train, y_valid, trainidt_train, trainidt_valid = train_test_split(X, y, trainidt, random_state=12)"]},{"cell_type":"markdown","metadata":{},"source":["## Adding a Dimension"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:16:46.537064Z","iopub.status.busy":"2021-10-18T18:16:46.536693Z","iopub.status.idle":"2021-10-18T18:16:48.991567Z","shell.execute_reply":"2021-10-18T18:16:48.990589Z","shell.execute_reply.started":"2021-10-18T18:16:46.537005Z"},"trusted":true},"outputs":[],"source":["X_train = tf.expand_dims(X_train, axis=-1)\n","X_valid = tf.expand_dims(X_valid, axis=-1)\n","X_train.shape"]},{"cell_type":"markdown","metadata":{},"source":["## One-hot encode labels"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:16:54.758000Z","iopub.status.busy":"2021-10-18T18:16:54.757694Z","iopub.status.idle":"2021-10-18T18:16:54.766267Z","shell.execute_reply":"2021-10-18T18:16:54.765130Z","shell.execute_reply.started":"2021-10-18T18:16:54.757972Z"},"trusted":true},"outputs":[],"source":["y_train = to_categorical(y_train)\n","y_valid = to_categorical(y_valid)"]},{"cell_type":"markdown","metadata":{},"source":["# Tunable Model"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:17:00.318071Z","iopub.status.busy":"2021-10-18T18:17:00.317235Z","iopub.status.idle":"2021-10-18T18:17:00.392102Z","shell.execute_reply":"2021-10-18T18:17:00.391295Z","shell.execute_reply.started":"2021-10-18T18:17:00.318002Z"},"trusted":true},"outputs":[],"source":["import keras_tuner as kt\n","\n","\n","def make_model(hp):\n","    inputs = keras.Input(shape=X_train.shape[1:])\n","    \n","    x = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n","\n","#     num_block = hp.Int('num_block', min_value=2, max_value=5, step=1)\n","#     num_filters = hp.Int('num_filters', min_value=32, max_value=128, step=32)\n","    \n","#     x = keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"relu\", name=\"Conv_1\")(x)\n","    x = keras.layers.Conv2D(filters=hp.Int('units_Conv_1_' + str(0),\n","                                            min_value=64,\n","                                            max_value=256,\n","                                            step=32),\n","                            kernel_size=(4, 4),\n","                            activation=\"relu\", \n","                            name=\"Conv_1\")(x)\n","\n","    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n","\n","#     x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x)\n","    x = keras.layers.Conv2D(filters=hp.Int('units_conv2_' + str(1),\n","                                            min_value=16,\n","                                            max_value=128,\n","                                            step=16),\n","                            kernel_size=(2, 2),\n","                            activation=\"relu\",\n","                            name=\"Conv_2\")(x)\n","\n","    x = keras.layers.MaxPool2D(pool_size=(1, 1))(x)\n","    \n","#     for i in range(num_block):\n","#         x = keras.layers.Conv2D(num_filters, \n","#                                 kernel_size=(4, 4),\n","#                                 activation=\"relu\",\n","#                                 )(x)\n","    \n","#         x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n","\n","#     x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x)\n","#     x = keras.layers.MaxPool2D(pool_size=(1, 1))(x)\n","\n","#     h = keras.layers.Dropout(0.1)(h)\n","    x = layers.Dropout(\n","        hp.Float('dense_dropout', min_value=0., max_value=0.7)\n","    )(x)\n","    x = keras.layers.Flatten()(x)\n","#     reduction_type = hp.Choice('reduction_type', ['flatten', 'avg'])\n","#     if reduction_type == 'flatten':\n","#         x = layers.Flatten()(x)\n","#     else:\n","#         x = layers.GlobalAveragePooling2D()(x)\n","        \n","#     x = keras.layers.Dense(32, activation=\"relu\")(x)\n","    x = layers.Dense(\n","        units=hp.Int('num_dense_units', min_value=16, max_value=64, step=8),\n","        activation='relu'\n","    )(x)\n","\n","    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n","\n","    model = keras.Model(inputs, outputs)\n","\n","    roc_auc = tf.keras.metrics.AUC(name='roc_auc', curve='ROC')\n","\n","    model.compile(\n","        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[roc_auc]\n","    )\n","    model.summary()\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["# Hyperparameter Search"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:28:37.065343Z","iopub.status.busy":"2021-10-18T18:28:37.064474Z","iopub.status.idle":"2021-10-18T18:29:18.875801Z","shell.execute_reply":"2021-10-18T18:29:18.874811Z","shell.execute_reply.started":"2021-10-18T18:28:37.065307Z"},"trusted":true},"outputs":[],"source":["tuner = kt.tuners.BayesianOptimization(\n","    make_model,\n","    objective='val_loss',\n","    max_trials=1,  # Set to 5 to run quicker, but need 100+ for good results\n","    overwrite=True)\n","\n","callbacks=[keras.callbacks.EarlyStopping(monitor='val_roc_acc', mode='max', patience=3, baseline=0.9)]\n","\n","tuner.search(X_train, y_train, validation_split=0.2 ,callbacks=callbacks, verbose=1, epochs=20)"]},{"cell_type":"markdown","metadata":{},"source":["# Find the best epoch value"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:29:53.285961Z","iopub.status.busy":"2021-10-18T18:29:53.285643Z","iopub.status.idle":"2021-10-18T18:30:24.925545Z","shell.execute_reply":"2021-10-18T18:30:24.924524Z","shell.execute_reply.started":"2021-10-18T18:29:53.285932Z"},"trusted":true},"outputs":[],"source":["best_hp = tuner.get_best_hyperparameters()[0]\n","best_model = make_model(best_hp)\n","history = best_model.fit(X_train, y_train,validation_split=0.2, epochs=15)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:32:56.289050Z","iopub.status.busy":"2021-10-18T18:32:56.288732Z","iopub.status.idle":"2021-10-18T18:32:56.323221Z","shell.execute_reply":"2021-10-18T18:32:56.321853Z","shell.execute_reply.started":"2021-10-18T18:32:56.289006Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.models import model_from_json\n","import numpy\n","import os\n","\n","# serialize model to JSON\n","model_json = best_model.to_json()\n","with open(\"best_model.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","best_model.save_weights(\"model.h5\")\n","print(\"Saved model to disk\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:40:31.588922Z","iopub.status.busy":"2021-10-18T18:40:31.588624Z","iopub.status.idle":"2021-10-18T18:40:31.719398Z","shell.execute_reply":"2021-10-18T18:40:31.714654Z","shell.execute_reply.started":"2021-10-18T18:40:31.588894Z"},"trusted":true},"outputs":[],"source":["# load json and create model\n","json_file = open('best_model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"model.h5\")\n","print(\"Loaded model from disk\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:51:32.436233Z","iopub.status.busy":"2021-10-18T18:51:32.435857Z","iopub.status.idle":"2021-10-18T18:51:32.791456Z","shell.execute_reply":"2021-10-18T18:51:32.790450Z","shell.execute_reply.started":"2021-10-18T18:51:32.436203Z"},"trusted":true},"outputs":[],"source":["y_pred = loaded_model.predict(X_valid)\n","\n","pred = np.argmax(y_pred, axis=1)\n","\n","result = pd.DataFrame(trainidt_valid)\n","result[1] = pred\n","\n","result.columns = [\"BraTS21ID\", \"MGMT_value\"]\n","result2 = result.groupby(\"BraTS21ID\", as_index=False).mean()\n","\n","result2 = result2.merge(train_df, on=\"BraTS21ID\")\n","auc = roc_auc_score(\n","    result2.MGMT_value_y,\n","    result2.MGMT_value_x,\n",")\n","print(f\"Validation AUC={auc}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:52:09.692390Z","iopub.status.busy":"2021-10-18T18:52:09.692077Z","iopub.status.idle":"2021-10-18T18:52:09.939578Z","shell.execute_reply":"2021-10-18T18:52:09.938603Z","shell.execute_reply.started":"2021-10-18T18:52:09.692359Z"},"trusted":true},"outputs":[],"source":["y_pred = loaded_model.predict(X_test)\n","\n","pred = np.argmax(y_pred, axis=1) #\n","\n","result = pd.DataFrame(testidt)\n","result[1] = pred\n","pred"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-10-18T18:52:40.707775Z","iopub.status.busy":"2021-10-18T18:52:40.707461Z","iopub.status.idle":"2021-10-18T18:52:40.741006Z","shell.execute_reply":"2021-10-18T18:52:40.739715Z","shell.execute_reply.started":"2021-10-18T18:52:40.707745Z"},"trusted":true},"outputs":[],"source":["result.columns=['BraTS21ID','MGMT_value']\n","\n","result2 = result.groupby('BraTS21ID',as_index=False).mean()\n","result2['BraTS21ID'] = sample_submission['BraTS21ID']\n","\n","result2['MGMT_value'] = result2['MGMT_value'] # No rounding\n","result2.to_csv('submission.csv',index=False)\n","result2"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":4}
